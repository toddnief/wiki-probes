{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle gpu leakage issue on DSI cluster\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from baukit import TraceDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm GPUs are working properly and set default device explicitly\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.set_device(0) # Sets the default device for tensors to be the first GPU.\n",
    "device = \"cuda:0\"\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d84b2ccee24aeebea6b5c7523e6b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MODEL = \"/net/projects/veitch/LLMs/llama2-based-models/llama2-hf/Llama-2-7b-chat-hf\"\n",
    "MODEL = \"/net/projects/veitch/LLMs/llama1-based-models/alpaca-7b\"\n",
    "\n",
    "tokenizer = transformers.LlamaTokenizer.from_pretrained(MODEL)\n",
    "model = transformers.LlamaForCausalLM.from_pretrained(MODEL, low_cpu_mem_usage=True, torch_dtype=torch.float16, device_map=\"auto\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dictionary for decoding tokens\n",
    "vocab = tokenizer.get_vocab()\n",
    "id_to_token = {id: token for token, id in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Please say yes only if it costs between 3.22 and 5.76 dollars, otherwise no.\n",
      "\n",
      "### Input:\n",
      "9.30 dollars\n",
      "\n",
      "### Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Any prompt will do to demonstrate. This prompt is 82 tokens long.\n",
    "\n",
    "template = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Please say yes only if it costs between {:.2f} and {:.2f} dollars, otherwise no.\n",
    "\n",
    "### Input:\n",
    "{:.2f} dollars\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(3.22,5.76,9.30)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just generate some prompts for demonstration\n",
    "# You'd probably save a dataset of prompts, and load those from a file.\n",
    "\n",
    "def generate_prompts(template,n=1000,include_bounds=False):\n",
    "    \"Replicates the same distribution as BDAS paper.\"\n",
    "    for i in range(n):\n",
    "        # Generate the lower bound, upper bound, and input value\n",
    "        lower_bound = np.round(np.random.uniform(0.00,7.49),2)\n",
    "        max_ub = np.min([lower_bound+7.5,9.99])\n",
    "        upper_bound = np.round(np.random.uniform(lower_bound+2.5,max_ub),2)\n",
    "        diff = np.round(upper_bound - lower_bound,2)\n",
    "        assert 2.5 <= diff and diff <= 7.5, (lower_bound, max_ub, upper_bound, diff)\n",
    "        input_value = np.round(np.random.uniform(0.00,9.99),2)\n",
    "\n",
    "        # Generate the prompt\n",
    "        prompt = template.format(lower_bound,upper_bound,input_value)\n",
    "        if include_bounds:\n",
    "            yield (lower_bound,upper_bound,input_value,prompt)\n",
    "        else:\n",
    "            yield prompt\n",
    "\n",
    "prompts = [p for p in generate_prompts(template,n=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(prompts,tokenizer,model,device,layer=\"all\"):\n",
    "    \"\"\"Returns a Numpy array of residual stream activations. \n",
    "    Based on https://github.com/likenneth/honest_llama\n",
    "    \n",
    "    David's uncertainties: I think these are the activations before the MLP sublayer?\n",
    "    \"\"\"\n",
    "    tokenized = tokenizer(prompts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = tokenized.input_ids.to(device)\n",
    "    attention_mask = tokenized.attention_mask.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    outputs = model(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask, output_hidden_states = True\n",
    "    )\n",
    "    hidden_states = outputs.hidden_states\n",
    "    if layer == \"all\":\n",
    "         # (num_layers, batch_size, seq_length, hidden_dim)\n",
    "        hidden_states = torch.stack(hidden_states, dim = 0).squeeze()\n",
    "        hidden_states = hidden_states.detach().cpu().numpy()\n",
    "    else:\n",
    "         # (batch_size, seq_length, hidden_dim)\n",
    "        hidden_states = hidden_states[layer].detach().cpu().numpy()\n",
    "    return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 82, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Single prompt, layer 15\n",
    "hidden_states = get_activations(prompts[:1],tokenizer,model,device,layer=15)\n",
    "print(hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 82, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Single prompt, all layers. \n",
    "# Note that in this case the shape drops the singluar batch_size dimension. Maybe we should adjust this behavior. But our use case is probing, which is multiple prompts.\n",
    "hidden_states = get_activations(prompts[:1],tokenizer,model,device)\n",
    "print(hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 82, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Multiple prompt, layer 15\n",
    "hidden_states = get_activations(prompts,tokenizer,model,device,layer=15)\n",
    "print(hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 10, 82, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Multiple prompt, all layers\n",
    "hidden_states = get_activations(prompts,tokenizer,model,device)\n",
    "print(hidden_states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Some Probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = \"categories\" # choices are \"title\" and \"categories\"\n",
    "DATA_FOLDER = \"data/\"\n",
    "TRAIN_DATA = DATA_FOLDER + \"train-10-articles.csv\"\n",
    "VAL_DATA = DATA_FOLDER + \"val-10-articles.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATA)\n",
    "df_val = pd.read_csv(VAL_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitted_label_encoder(df, labels=LABELS):\n",
    "    if LABELS == \"categories\":\n",
    "        from ast import literal_eval\n",
    "        unique_labels = set()\n",
    "        for item in df_train['categories'].tolist():\n",
    "            categories = literal_eval(item)\n",
    "            for cat in categories:\n",
    "                unique_labels.update([cat])\n",
    "        unique_labels = list(unique_labels)\n",
    "    elif LABELS == \"title\":\n",
    "        unique_labels = list(df_train['title'].drop_duplicates())\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(unique_labels)\n",
    "\n",
    "    return label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = get_fitted_label_encoder(df_train)\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataloader(df, model, label_encoder, layer=-1, aggregation=\"max\", labels=LABELS, save=False, filename=DATA_FOLDER + \"dataset.pt\"):\n",
    "    if labels==\"title\":\n",
    "        df['label_encoded'] = label_encoder.transform(df['title'])\n",
    "    elif labels==\"categories\":\n",
    "        # TODO: set up this label parsing as a function\n",
    "        from ast import literal_eval\n",
    "        encoded_labels = []\n",
    "        for item in df['categories'].tolist():\n",
    "            categories = literal_eval(item)\n",
    "            encoded_labels.append(label_encoder.transform(categories).tolist())\n",
    "        df['label_encoded'] = encoded_labels\n",
    "\n",
    "        def list_to_binary_vector(lst, dim=len(label_encoder.classes_)):\n",
    "            return [1 if i in lst else 0 for i in range(dim)]\n",
    "\n",
    "        # Assuming df['label_encoded'] is already a list of integers\n",
    "        df['binary_labels'] = df['label_encoded'].apply(list_to_binary_vector)\n",
    "\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    for i, row in df.iterrows():\n",
    "        hidden_states = get_activations(row.text,tokenizer,model,device)\n",
    "        if aggregation == \"max\":\n",
    "            x = np.max(hidden_states[layer,:,:], axis=0)\n",
    "        elif aggregation == \"mean\":\n",
    "            x = np.mean(hidden_states[layer,:,:], axis=0)\n",
    "        Xs.append(x)\n",
    "        if labels == \"categories\":\n",
    "            ys.append(row.binary_labels)\n",
    "        elif labels == \"title\":\n",
    "            ys.append(row.label_encoded)\n",
    "    \n",
    "    Xs_t = Tensor(np.asarray(Xs)).float()\n",
    "    ys_t = Tensor(np.asarray(ys)).float() if labels == \"categories\" else Tensor(np.asarray(ys)).long()\n",
    "    tensor_dataset = TensorDataset(Xs_t, ys_t)\n",
    "\n",
    "    if save:\n",
    "        torch.save(tensor_dataset, filename)\n",
    "\n",
    "    return DataLoader(tensor_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (986) does not match length of index (31)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/tnief/wiki-probes/get_activations.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bi001.ds/home/tnief/wiki-probes/get_activations.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_loader \u001b[39m=\u001b[39m df_to_dataloader(df_train, model, label_encoder, aggregation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m, layer\u001b[39m=\u001b[39mLAYER)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bi001.ds/home/tnief/wiki-probes/get_activations.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m val_loader \u001b[39m=\u001b[39m df_to_dataloader(df_val, model, label_encoder, aggregation\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m\"\u001b[39;49m, layer\u001b[39m=\u001b[39;49mLAYER)\n",
      "\u001b[1;32m/home/tnief/wiki-probes/get_activations.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bi001.ds/home/tnief/wiki-probes/get_activations.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     categories \u001b[39m=\u001b[39m literal_eval(item)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi001.ds/home/tnief/wiki-probes/get_activations.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     encoded_labels\u001b[39m.\u001b[39mappend(label_encoder\u001b[39m.\u001b[39mtransform(categories)\u001b[39m.\u001b[39mtolist())\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bi001.ds/home/tnief/wiki-probes/get_activations.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mlabel_encoded\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m encoded_labels\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi001.ds/home/tnief/wiki-probes/get_activations.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlist_to_binary_vector\u001b[39m(lst, dim\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(label_encoder\u001b[39m.\u001b[39mclasses_)):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi001.ds/home/tnief/wiki-probes/get_activations.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m i \u001b[39min\u001b[39;00m lst \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(dim)]\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/pandas/core/frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3947\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3948\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3949\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3950\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/pandas/core/frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4135\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4136\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4141\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4142\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4143\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4145\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4146\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4147\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4148\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4149\u001b[0m     ):\n\u001b[1;32m   4150\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4151\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/pandas/core/frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4867\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4869\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4870\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4871\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/pandas/core/common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (986) does not match length of index (31)"
     ]
    }
   ],
   "source": [
    "train_loader = df_to_dataloader(df_train, model, label_encoder, aggregation=\"max\", layer=LAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = df_to_dataloader(df_val, model, label_encoder, aggregation=\"max\", layer=LAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, n_classes=len(label_encoder.classes_)):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(4096, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_classes=len(label_encoder.classes_)):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(4096, 120)\n",
    "        self.fc2 = nn.Linear(120, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        init.xavier_normal_(m.weight)\n",
    "        init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(\n",
       "  (fc1): Linear(in_features=4096, out_features=56, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = \"linear\" # choices are \"linear\" or \"mlp\"\n",
    "if MODEL == \"linear\":\n",
    "    probe = Linear()\n",
    "elif MODEL == \"mlp\":\n",
    "    probe = MLP()\n",
    "probe.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LABELS == \"categories\":\n",
    "    criterion = BCEWithLogitsLoss(pos_weight=Tensor(torch.ones(len(label_encoder.classes_)) * 20))\n",
    "elif LABELS == \"title\":\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO: what optimizer should we actually use\n",
    "# optimizer = optim.AdamW(probe.parameters(), lr=0.001)\n",
    "optimizer = optim.SGD(probe.parameters(), lr=.001, momentum=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][5] loss: 0.487\n",
      "[Validation][5] loss: 0.923\n",
      "[Predicted Validation Labels]: 404\n",
      "[Training][10] loss: 0.246\n",
      "[Validation][10] loss: 0.631\n",
      "[Predicted Validation Labels]: 268\n",
      "[Training][15] loss: 0.159\n",
      "[Validation][15] loss: 0.599\n",
      "[Predicted Validation Labels]: 232\n",
      "[Training][20] loss: 0.119\n",
      "[Validation][20] loss: 0.539\n",
      "[Predicted Validation Labels]: 217\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = 0\n",
    "for epoch in range(EPOCHS):  \n",
    "    probe.train()\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = probe(inputs)\n",
    "        if torch.all(labels != labels[0]):\n",
    "            print(\"All labels are not the same: \", labels)\n",
    "        if torch.all(outputs != outputs[0]):\n",
    "            print(\"All outputs are not the same: \", outputs)\n",
    "        if LABELS == \"categories\":\n",
    "            pos_labels = labels.sum().item()\n",
    "            neg_labels = labels.numel() - pos_labels\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        val_loss = 0.0\n",
    "        val_count = 0\n",
    "        predicted_labels = 0\n",
    "        probe.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(val_loader):  \n",
    "                inputs, labels = data\n",
    "                outputs = probe(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_count += 1\n",
    "                # TODO: add validation accuracy\n",
    "                if LABELS == \"categories\":\n",
    "                    predicted_labels += (torch.sigmoid(outputs) > .5).int().sum().item()\n",
    "\n",
    "        print(f'[Training][{epoch + 1}] loss: {train_loss / len(train_loader):.3f}')\n",
    "        print(f'[Validation][{epoch + 1}] loss: {val_loss / val_count:.3f}')\n",
    "        if LABELS == \"categories\":\n",
    "            print(f'[Predicted Validation Labels]: {predicted_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 56 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/tnief/wiki-probes/get_activations.ipynb Cell 29\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bi001.ds/home/tnief/wiki-probes/get_activations.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(probe(inputs), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bi001.ds/home/tnief/wiki-probes/get_activations.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m j, lbl \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(labels):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bi001.ds/home/tnief/wiki-probes/get_activations.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     lbl \u001b[39m=\u001b[39m lbl\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi001.ds/home/tnief/wiki-probes/get_activations.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     correct \u001b[39m=\u001b[39m lbl \u001b[39m==\u001b[39m preds[j]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi001.ds/home/tnief/wiki-probes/get_activations.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(lbl, preds[j]\u001b[39m.\u001b[39mitem(), correct\u001b[39m.\u001b[39mitem())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 56 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# TODO: add something to see which classes get confused\n",
    "# TODO: fix this to handle categories\n",
    "\n",
    "correct_total = 0\n",
    "correct_per_class = defaultdict(int)\n",
    "for i, (inputs, labels) in enumerate(val_loader):\n",
    "    preds = torch.max(probe(inputs), dim=1)[1]\n",
    "    for j, lbl in enumerate(labels):\n",
    "        lbl = lbl.item()\n",
    "        correct = lbl == preds[j]\n",
    "        print(lbl, preds[j].item(), correct.item())\n",
    "        correct_per_class[lbl] += correct.item()\n",
    "        correct_total += correct\n",
    "    # print(f\"Batch {i+1}\")\n",
    "    # print(\"Labels:\", labels)\n",
    "    # print(\"Predicted Labels:\", preds)\n",
    "accuracy = (correct_total/len(val_loader.dataset)).item() * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "for k,v in sorted(correct_per_class.items()):\n",
    "    print(f\"{k}: {v} correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
