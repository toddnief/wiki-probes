{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# r = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tnief/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from datasets import load_dataset\n",
    "# import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import transformers\n",
    "from baukit import TraceDict\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.set_device(0) # Sets the default device for tensors to be the first GPU.\n",
    "device = \"cuda:0\"\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [02:06<00:00, 42.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "\n",
    "# MODEL = \"/net/projects/veitch/LLMs/llama2-based-models/llama2-hf/Llama-2-7b-chat-hf\"\n",
    "MODEL = \"/net/projects/veitch/LLMs/llama1-based-models/alpaca-7b\"\n",
    "\n",
    "tokenizer = transformers.LlamaTokenizer.from_pretrained(MODEL)\n",
    "model = transformers.LlamaForCausalLM.from_pretrained(MODEL, low_cpu_mem_usage=True, torch_dtype=torch.float16, device_map=\"auto\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Please say yes only if it costs between 3.22 and 5.76 dollars, otherwise no.\n",
      "\n",
      "### Input:\n",
      "9.30 dollars\n",
      "\n",
      "### Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Any prompt will do to demonstrate. This prompt is 82 tokens long.\n",
    "\n",
    "template = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Please say yes only if it costs between {:.2f} and {:.2f} dollars, otherwise no.\n",
    "\n",
    "### Input:\n",
    "{:.2f} dollars\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(3.22,5.76,9.30)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just generate some prompts for demonstration\n",
    "# You'd probably save a dataset of prompts, and load those from a file.\n",
    "\n",
    "def generate_prompts(template,n=1000,include_bounds=False):\n",
    "    \"Replicates the same distribution as BDAS paper.\"\n",
    "    for i in range(n):\n",
    "        # Generate the lower bound, upper bound, and input value\n",
    "        lower_bound = np.round(np.random.uniform(0.00,7.49),2)\n",
    "        max_ub = np.min([lower_bound+7.5,9.99])\n",
    "        upper_bound = np.round(np.random.uniform(lower_bound+2.5,max_ub),2)\n",
    "        diff = np.round(upper_bound - lower_bound,2)\n",
    "        assert 2.5 <= diff and diff <= 7.5, (lower_bound, max_ub, upper_bound, diff)\n",
    "        input_value = np.round(np.random.uniform(0.00,9.99),2)\n",
    "\n",
    "        # Generate the prompt\n",
    "        prompt = template.format(lower_bound,upper_bound,input_value)\n",
    "        if include_bounds:\n",
    "            yield (lower_bound,upper_bound,input_value,prompt)\n",
    "        else:\n",
    "            yield prompt\n",
    "\n",
    "prompts = [p for p in generate_prompts(template,n=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(prompts,tokenizer,model,device,layer=\"all\"):\n",
    "    \"\"\"Returns a Numpy array of residual stream activations. \n",
    "    Based on https://github.com/likenneth/honest_llama\n",
    "    \n",
    "    David's uncertainties: I think these are the activations before the MLP sublayer?\n",
    "    \"\"\"\n",
    "    # input_ids = tokenizer(prompts, padding=True, truncation=True, return_tensors=\"pt\").input_ids.to(device)\n",
    "    # attention_mask = tokenizer(prompt, return_tensors=\"pt\").attention_mask.to(device)\n",
    "\n",
    "    tokenized = tokenizer(prompts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = tokenized.input_ids.to(device)\n",
    "    attention_mask = tokenized.attention_mask.to(device)\n",
    "\n",
    "    # print(f\"Model on: {model.device if hasattr(model, 'device') else next(model.parameters()).device}\")\n",
    "    # print(f\"Input IDs on: {input_ids.device}\")\n",
    "    # print(f\"Attention Mask on: {attention_mask.device}\")\n",
    "\n",
    "    # print(tokenizer.convert_ids_to_tokens(tokenized[\"input_ids\"][0]))\n",
    "\n",
    "    model.eval()\n",
    "    outputs = model(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask, output_hidden_states = True\n",
    "    )\n",
    "    hidden_states = outputs.hidden_states\n",
    "    if layer == \"all\":\n",
    "         # (num_layers, batch_size, seq_length, hidden_dim)\n",
    "        hidden_states = torch.stack(hidden_states, dim = 0).squeeze()\n",
    "        hidden_states = hidden_states.detach().cpu().numpy()\n",
    "    else:\n",
    "         # (batch_size, seq_length, hidden_dim)\n",
    "        hidden_states = hidden_states[layer].detach().cpu().numpy()\n",
    "    return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 82, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Single prompt, layer 15\n",
    "hidden_states = get_activations(prompts[:1],tokenizer,model,device,layer=15)\n",
    "print(hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 82, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Single prompt, all layers. \n",
    "# Note that in this case the shape drops the singluar batch_size dimension. Maybe we should adjust this behavior. But our use case is probing, which is multiple prompts.\n",
    "hidden_states = get_activations(prompts[:1],tokenizer,model,device)\n",
    "print(hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 82, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Multiple prompt, layer 15\n",
    "hidden_states = get_activations(prompts,tokenizer,model,device,layer=15)\n",
    "print(hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 10, 82, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Multiple prompt, all layers\n",
    "hidden_states = get_activations(prompts,tokenizer,model,device)\n",
    "print(hidden_states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a supervised dataset of (prompts,labels), then to train a probe, you'll just replace the prompts with the activations in the learning objective. So you'll train a classifier on (activations,labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import Tensor\n",
    "from datasets import Dataset\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch.nn import BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = \"title\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/parsed-paragraphs-train.csv\")\n",
    "df_test = pd.read_csv(\"data/parsed-paragraphs-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: hacky way to get unique labels - set up pipeline to actually handle this well\n",
    "\n",
    "if LABELS == \"categories\":\n",
    "    from ast import literal_eval\n",
    "\n",
    "    unique_labels = set()\n",
    "    for item in df_train['label_list'].tolist():\n",
    "        for sub_item in item:\n",
    "            labels = literal_eval(sub_item)\n",
    "            unique_labels.update(labels)\n",
    "\n",
    "    unique_labels = list(unique_labels)\n",
    "elif LABELS == \"title\":\n",
    "    unique_labels = list(df_train['title'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anarchism',\n",
       " 'Albedo',\n",
       " 'A',\n",
       " 'Alabama',\n",
       " 'Achilles',\n",
       " 'Abraham Lincoln',\n",
       " 'Aristotle',\n",
       " 'An American in Paris',\n",
       " 'Academy Award for Best Production Design',\n",
       " 'Academy Awards',\n",
       " 'Animalia (book)',\n",
       " 'International Atomic Time',\n",
       " 'Altruism',\n",
       " 'Ayn Rand',\n",
       " 'Alain Connes',\n",
       " 'Allan Dwan',\n",
       " 'Algeria',\n",
       " 'List of Atlas Shrugged characters',\n",
       " 'Anthropology',\n",
       " 'Agricultural science']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataloader(df, model, labels=LABELS, save=False):\n",
    "    if labels==\"title\":\n",
    "        unique_labels = list(df_train['title'].drop_duplicates())\n",
    "        label_encoder = LabelEncoder()\n",
    "        df['label_encoded'] = label_encoder.fit_transform(df['title'])\n",
    "    elif labels==\"categories\":\n",
    "        df['label_list'] = df['label'].apply(lambda x: x.split('|'))\n",
    "        unique_labels = set()\n",
    "        for item in df_train['label_list'].tolist():\n",
    "            for sub_item in item:\n",
    "                labels = literal_eval(sub_item)\n",
    "                unique_labels.update(labels)\n",
    "\n",
    "        unique_labels = list(unique_labels)\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "        label_encoder.fit(unique_labels)\n",
    "\n",
    "        encoded_labels = []\n",
    "        for item in df_train['label_list'].tolist():\n",
    "            for sub_item in item:\n",
    "                labels = literal_eval(sub_item)\n",
    "                encoded_labels.append(label_encoder.transform(labels).tolist())\n",
    "        df['label_encoded'] = encoded_labels\n",
    "\n",
    "        def list_to_binary_vector(lst, dim=len(unique_labels)):\n",
    "            return [1 if i in lst else 0 for i in range(dim)]\n",
    "\n",
    "        # Assuming df['label_encoded'] is already a list of integers\n",
    "        df['binary_labels'] = df['label_encoded'].apply(list_to_binary_vector)\n",
    "\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    for i, row in df.iterrows():\n",
    "        hidden_states = get_activations(row.text,tokenizer,model,device)\n",
    "        Xs.append(hidden_states[:,0,:]) # take only the <s> token\n",
    "        if labels == \"categories\":\n",
    "            ys.append(row.binary_labels)\n",
    "        elif labels == \"title\":\n",
    "            ys.append(row.label_encoded)\n",
    "    \n",
    "    Xs_t = Tensor(Xs).float()\n",
    "    ys_t = Tensor(np.asarray(ys)).float() if labels == \"categories\" else Tensor(np.asarray(ys)).long()\n",
    "\n",
    "    tensor_dataset = TensorDataset(Xs_t, ys_t)\n",
    "\n",
    "    if save:\n",
    "        torch.save(tensor_dataset, 'data/example_dataset.pt')\n",
    "\n",
    "    return DataLoader(tensor_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/scratch/tnief/tmp/ipykernel_3105227/2820583812.py:42: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  Xs_t = Tensor(Xs).float()\n"
     ]
    }
   ],
   "source": [
    "train_loader = df_to_dataloader(df_train, model)\n",
    "test_loader = df_to_dataloader(df_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, n_classes=len(unique_labels)):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(33*4096, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_classes=len(unique_labels)):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(33*4096, 120)\n",
    "        self.fc2 = nn.Linear(120, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        init.xavier_normal_(m.weight)\n",
    "        init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha=.5, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "        return F_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=135168, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = Linear()\n",
    "mlp = MLP()\n",
    "probe = mlp\n",
    "probe.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "if LABELS == \"catgories\":\n",
    "    criterion = BCEWithLogitsLoss(pos_weight=Tensor(torch.ones(len(unique_labels)) * 20))\n",
    "elif LABELS == \"title\":\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = optim.AdamW(probe.parameters(), lr=0.001)\n",
    "optimizer = optim.SGD(probe.parameters(), lr=.001, momentum=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][5] loss: 2.996\n",
      "[Validation][5] loss: 2.996\n",
      "[Training][10] loss: 2.996\n",
      "[Validation][10] loss: 2.996\n",
      "[Training][15] loss: 2.996\n",
      "[Validation][15] loss: 2.996\n",
      "[Training][20] loss: 2.996\n",
      "[Validation][20] loss: 2.996\n",
      "[Training][25] loss: 2.996\n",
      "[Validation][25] loss: 2.996\n",
      "[Training][30] loss: 2.996\n",
      "[Validation][30] loss: 2.996\n",
      "[Training][35] loss: 2.996\n",
      "[Validation][35] loss: 2.996\n",
      "[Training][40] loss: 2.996\n",
      "[Validation][40] loss: 2.996\n",
      "[Training][45] loss: 2.996\n",
      "[Validation][45] loss: 2.996\n",
      "[Training][50] loss: 2.996\n",
      "[Validation][50] loss: 2.996\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = 0\n",
    "for epoch in range(50):  \n",
    "    probe.train()\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = probe(inputs)\n",
    "        if LABELS == \"categories\":\n",
    "            pos_labels = labels.sum().item()\n",
    "            neg_labels = labels.numel() - pos_labels\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        val_loss = 0.0\n",
    "        val_count = 0\n",
    "        predicted_labels = 0\n",
    "        probe.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_loader):  \n",
    "                inputs, labels = data\n",
    "                outputs = probe(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_count += 1\n",
    "                if LABELS == \"categories\":\n",
    "                    predicted_labels += (torch.sigmoid(outputs) > .5).int().sum().item()\n",
    "\n",
    "        print(f'[Training][{epoch + 1}] loss: {train_loss / len(train_loader):.3f}')\n",
    "        print(f'[Validation][{epoch + 1}] loss: {val_loss / val_count:.3f}')\n",
    "        if LABELS == \"categories\":\n",
    "            print(f'[Predicted Validation Labels]: {predicted_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Labels: tensor([ 8,  2, 16,  5])\n",
      "Batch 2\n",
      "Labels: tensor([ 3, 12, 12,  6])\n",
      "Batch 3\n",
      "Labels: tensor([ 3, 13,  8,  1])\n",
      "Batch 4\n",
      "Labels: tensor([11, 17,  5, 17])\n",
      "Batch 5\n",
      "Labels: tensor([1, 6, 2, 9])\n",
      "Batch 6\n",
      "Labels: tensor([11, 18, 14, 19])\n",
      "Batch 7\n",
      "Labels: tensor([ 0, 18,  9,  4])\n",
      "Batch 8\n",
      "Labels: tensor([ 7, 13,  4,  7])\n",
      "Batch 9\n",
      "Labels: tensor([14, 10, 16, 15])\n",
      "Batch 10\n",
      "Labels: tensor([ 0, 15, 19, 10])\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs, labels) in enumerate(train_loader):\n",
    "    print(f\"Batch {i+1}\")\n",
    "    print(\"Labels:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 15, 14, 11])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17, 17, 17, 17])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, predicted_labels = torch.max(probe(data), dim=1)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13, 19, 16, 12])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.sigmoid(mlp(data))[0] > .5).int().sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.sigmoid(mlp(data))[0] > .5).int().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
