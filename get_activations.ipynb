{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle gpu leakage issue on DSI cluster\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tnief/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from baukit import TraceDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.set_device(0) # Sets the default device for tensors to be the first GPU.\n",
    "device = \"cuda:0\"\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:12<00:00,  4.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# MODEL = \"/net/projects/veitch/LLMs/llama2-based-models/llama2-hf/Llama-2-7b-chat-hf\"\n",
    "MODEL = \"/net/projects/veitch/LLMs/llama1-based-models/alpaca-7b\"\n",
    "\n",
    "tokenizer = transformers.LlamaTokenizer.from_pretrained(MODEL)\n",
    "model = transformers.LlamaForCausalLM.from_pretrained(MODEL, low_cpu_mem_usage=True, torch_dtype=torch.float16, device_map=\"auto\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dictionary for decoding tokens\n",
    "vocab = tokenizer.get_vocab()\n",
    "id_to_token = {id: token for token, id in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Please say yes only if it costs between 3.22 and 5.76 dollars, otherwise no.\n",
      "\n",
      "### Input:\n",
      "9.30 dollars\n",
      "\n",
      "### Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Any prompt will do to demonstrate. This prompt is 82 tokens long.\n",
    "\n",
    "template = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Please say yes only if it costs between {:.2f} and {:.2f} dollars, otherwise no.\n",
    "\n",
    "### Input:\n",
    "{:.2f} dollars\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "prompt = template.format(3.22,5.76,9.30)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just generate some prompts for demonstration\n",
    "# You'd probably save a dataset of prompts, and load those from a file.\n",
    "\n",
    "def generate_prompts(template,n=1000,include_bounds=False):\n",
    "    \"Replicates the same distribution as BDAS paper.\"\n",
    "    for i in range(n):\n",
    "        # Generate the lower bound, upper bound, and input value\n",
    "        lower_bound = np.round(np.random.uniform(0.00,7.49),2)\n",
    "        max_ub = np.min([lower_bound+7.5,9.99])\n",
    "        upper_bound = np.round(np.random.uniform(lower_bound+2.5,max_ub),2)\n",
    "        diff = np.round(upper_bound - lower_bound,2)\n",
    "        assert 2.5 <= diff and diff <= 7.5, (lower_bound, max_ub, upper_bound, diff)\n",
    "        input_value = np.round(np.random.uniform(0.00,9.99),2)\n",
    "\n",
    "        # Generate the prompt\n",
    "        prompt = template.format(lower_bound,upper_bound,input_value)\n",
    "        if include_bounds:\n",
    "            yield (lower_bound,upper_bound,input_value,prompt)\n",
    "        else:\n",
    "            yield prompt\n",
    "\n",
    "prompts = [p for p in generate_prompts(template,n=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(prompts,tokenizer,model,device,layer=\"all\"):\n",
    "    \"\"\"Returns a Numpy array of residual stream activations. \n",
    "    Based on https://github.com/likenneth/honest_llama\n",
    "    \n",
    "    David's uncertainties: I think these are the activations before the MLP sublayer?\n",
    "    \"\"\"\n",
    "    tokenized = tokenizer(prompts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    input_ids = tokenized.input_ids.to(device)\n",
    "    attention_mask = tokenized.attention_mask.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    outputs = model(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask, output_hidden_states = True\n",
    "    )\n",
    "    hidden_states = outputs.hidden_states\n",
    "    if layer == \"all\":\n",
    "         # (num_layers, batch_size, seq_length, hidden_dim)\n",
    "        hidden_states = torch.stack(hidden_states, dim = 0).squeeze()\n",
    "        hidden_states = hidden_states.detach().cpu().numpy()\n",
    "    else:\n",
    "         # (batch_size, seq_length, hidden_dim)\n",
    "        hidden_states = hidden_states[layer].detach().cpu().numpy()\n",
    "    return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 82, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Single prompt, layer 15\n",
    "hidden_states = get_activations(prompts[:1],tokenizer,model,device,layer=15)\n",
    "print(hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 82, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Single prompt, all layers. \n",
    "# Note that in this case the shape drops the singluar batch_size dimension. Maybe we should adjust this behavior. But our use case is probing, which is multiple prompts.\n",
    "hidden_states = get_activations(prompts[:1],tokenizer,model,device)\n",
    "print(hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 82, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Multiple prompt, layer 15\n",
    "hidden_states = get_activations(prompts,tokenizer,model,device,layer=15)\n",
    "print(hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 10, 82, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Multiple prompt, all layers\n",
    "hidden_states = get_activations(prompts,tokenizer,model,device)\n",
    "print(hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check outputs\n",
    "test1 = get_activations(\"Circus peanuts\", tokenizer, model, device)\n",
    "test2 = get_activations(\"High dimensional vectors and machine learning\", tokenizer, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33, 6, 4096), (33, 7, 4096))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.shape, test2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Some Probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = \"title\" # other choice is \"categories\"\n",
    "DATA_FOLDER = \"data/\"\n",
    "TRAIN_DATA = DATA_FOLDER + \"train-10-articles.csv\"\n",
    "VAL_DATA = DATA_FOLDER + \"val-10-articles.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATA)\n",
    "df_val = pd.read_csv(VAL_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: hacky way to get unique labels - set up pipeline to actually handle this well\n",
    "if LABELS == \"categories\":\n",
    "    from ast import literal_eval\n",
    "\n",
    "    unique_labels = set()\n",
    "    for item in df_train['label_list'].tolist():\n",
    "        for sub_item in item:\n",
    "            labels = literal_eval(sub_item)\n",
    "            unique_labels.update(labels)\n",
    "\n",
    "    unique_labels = list(unique_labels)\n",
    "elif LABELS == \"title\":\n",
    "    unique_labels = list(df_train['title'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anarchism',\n",
       " 'Anthropology',\n",
       " 'Alchemy',\n",
       " 'Astronomer',\n",
       " 'Animation',\n",
       " 'Amphibian',\n",
       " 'Alaska',\n",
       " 'Agriculture',\n",
       " 'Algae',\n",
       " 'Appellate court']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataloader(df, model, labels=LABELS, save=False):\n",
    "    if labels==\"title\":\n",
    "        unique_labels = list(df_train['title'].drop_duplicates())\n",
    "        label_encoder = LabelEncoder()\n",
    "        df['label_encoded'] = label_encoder.fit_transform(df['title'])\n",
    "    elif labels==\"categories\":\n",
    "        df['label_list'] = df['label'].apply(lambda x: x.split('|'))\n",
    "        unique_labels = set()\n",
    "        for item in df_train['label_list'].tolist():\n",
    "            for sub_item in item:\n",
    "                labels = literal_eval(sub_item)\n",
    "                unique_labels.update(labels)\n",
    "\n",
    "        unique_labels = list(unique_labels)\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "        label_encoder.fit(unique_labels)\n",
    "\n",
    "        encoded_labels = []\n",
    "        for item in df_train['label_list'].tolist():\n",
    "            for sub_item in item:\n",
    "                labels = literal_eval(sub_item)\n",
    "                encoded_labels.append(label_encoder.transform(labels).tolist())\n",
    "        df['label_encoded'] = encoded_labels\n",
    "\n",
    "        def list_to_binary_vector(lst, dim=len(unique_labels)):\n",
    "            return [1 if i in lst else 0 for i in range(dim)]\n",
    "\n",
    "        # Assuming df['label_encoded'] is already a list of integers\n",
    "        df['binary_labels'] = df['label_encoded'].apply(list_to_binary_vector)\n",
    "\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    for i, row in df.iterrows():\n",
    "        hidden_states = get_activations(row.text,tokenizer,model,device)\n",
    "        # take only the activations from the final transformer layer\n",
    "        # TODO: set up principled way of doing mean, max, or some sort of pooling\n",
    "        # Xs.append(np.mean(hidden_states[-1,:,:], axis=0))\n",
    "        Xs.append(np.max(hidden_states[-1,:,:], axis=0))\n",
    "        if labels == \"categories\":\n",
    "            ys.append(row.binary_labels)\n",
    "        elif labels == \"title\":\n",
    "            ys.append(row.label_encoded)\n",
    "    \n",
    "    # TODO: fix this so you don't get the warning about this being slow\n",
    "    Xs_t = Tensor(Xs).float()\n",
    "    ys_t = Tensor(np.asarray(ys)).float() if labels == \"categories\" else Tensor(np.asarray(ys)).long()\n",
    "\n",
    "    tensor_dataset = TensorDataset(Xs_t, ys_t)\n",
    "\n",
    "    # TODO: add an argument for saving filename\n",
    "    if save:\n",
    "        torch.save(tensor_dataset, 'data/example_dataset.pt')\n",
    "\n",
    "    return DataLoader(tensor_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = df_to_dataloader(df_train, model)\n",
    "val_loader = df_to_dataloader(df_val, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, n_classes=len(unique_labels)):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(4096, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_classes=len(unique_labels)):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(4096, 120)\n",
    "        self.fc2 = nn.Linear(120, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        init.xavier_normal_(m.weight)\n",
    "        init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=4096, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = \"mlp\" # other choice is \"linear\"\n",
    "if MODEL == \"linear\":\n",
    "    probe = Linear()\n",
    "elif MODEL == \"mlp\":\n",
    "    probe = MLP()\n",
    "probe.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LABELS == \"categories\":\n",
    "    criterion = BCEWithLogitsLoss(pos_weight=Tensor(torch.ones(len(unique_labels)) * 20))\n",
    "elif LABELS == \"title\":\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO: what optimizer should we actually use\n",
    "# optimizer = optim.AdamW(probe.parameters(), lr=0.001)\n",
    "optimizer = optim.SGD(probe.parameters(), lr=.001, momentum=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][5] loss: 1.298\n",
      "[Validation][5] loss: 2.501\n",
      "[Training][10] loss: 0.259\n",
      "[Validation][10] loss: 3.247\n",
      "[Training][15] loss: 0.058\n",
      "[Validation][15] loss: 4.064\n",
      "[Training][20] loss: 0.019\n",
      "[Validation][20] loss: 4.254\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = 0\n",
    "for epoch in range(EPOCHS):  \n",
    "    probe.train()\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = probe(inputs)\n",
    "        if torch.all(labels != labels[0]):\n",
    "            print(\"All labels are not the same: \", labels)\n",
    "        if torch.all(outputs != outputs[0]):\n",
    "            print(\"All outputs are not the same: \", outputs)\n",
    "        if LABELS == \"categories\":\n",
    "            pos_labels = labels.sum().item()\n",
    "            neg_labels = labels.numel() - pos_labels\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        val_loss = 0.0\n",
    "        val_count = 0\n",
    "        predicted_labels = 0\n",
    "        probe.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(val_loader):  \n",
    "                inputs, labels = data\n",
    "                outputs = probe(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_count += 1\n",
    "                if LABELS == \"categories\":\n",
    "                    predicted_labels += (torch.sigmoid(outputs) > .5).int().sum().item()\n",
    "\n",
    "        print(f'[Training][{epoch + 1}] loss: {train_loss / len(train_loader):.3f}')\n",
    "        print(f'[Validation][{epoch + 1}] loss: {val_loss / val_count:.3f}')\n",
    "        if LABELS == \"categories\":\n",
    "            print(f'[Predicted Validation Labels]: {predicted_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Labels: tensor([7, 5, 3, 6])\n",
      "Predicted Labels: tensor([7, 6, 3, 2])\n",
      "Batch 2\n",
      "Labels: tensor([1, 1, 4, 9])\n",
      "Predicted Labels: tensor([1, 1, 5, 9])\n",
      "Batch 3\n",
      "Labels: tensor([0, 3, 6, 0])\n",
      "Predicted Labels: tensor([0, 3, 7, 0])\n",
      "Batch 4\n",
      "Labels: tensor([1, 9, 3, 7])\n",
      "Predicted Labels: tensor([1, 3, 3, 8])\n",
      "Batch 5\n",
      "Labels: tensor([4, 2, 5, 0])\n",
      "Predicted Labels: tensor([5, 2, 3, 0])\n",
      "Batch 6\n",
      "Labels: tensor([5, 2, 4, 6])\n",
      "Predicted Labels: tensor([6, 2, 5, 7])\n",
      "Batch 7\n",
      "Labels: tensor([7, 2, 8])\n",
      "Predicted Labels: tensor([5, 2, 9])\n",
      "Accuracy: 51.85\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i, (inputs, labels) in enumerate(val_loader):\n",
    "    preds = torch.max(probe(inputs), dim=1)[1]\n",
    "    correct += (preds == labels).sum()\n",
    "    print(f\"Batch {i+1}\")\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Predicted Labels:\", preds)\n",
    "accuracy = (correct/len(val_loader.dataset)).item() * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
