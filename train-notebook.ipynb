{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle gpu leakage issue on DSI cluster\n",
    "# ideally we shouldn't have to do this but leaving it for now in case the issue pops up again\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM, LlamaTokenizer\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "\n",
    "import scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm GPUs are working properly and set default device explicitly\n",
    "device = \"cuda:0\"\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## References ##\n",
    "# Huggingface docs: https://huggingface.co/docs/transformers/main/model_doc/llama#transformers.LlamaForCausalLM \n",
    "\n",
    "## modeling_llama.py ##\n",
    "# LlamaForCausalLM » https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/modeling_llama.py#L989 \n",
    "# forward » https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/modeling_llama.py#L989 \n",
    "\n",
    "## utils.py ##\n",
    "# GenerationMixin » https://github.com/huggingface/transformers/blob/main/src/transformers/generation/utils.py#L571\n",
    "# generate » https://github.com/huggingface/transformers/blob/main/src/transformers/generation/utils.py#L1432\n",
    "# greedy_search » https://github.com/huggingface/transformers/blob/main/src/transformers/generation/utils.py#L2447 \n",
    "# actual forward pass » https://github.com/huggingface/transformers/blob/main/src/transformers/generation/utils.py#L2614 \n",
    "\n",
    "class EditableLlama(LlamaForCausalLM):\n",
    "    def __init__(self, config, *args, **kwargs):\n",
    "        super().__init__(config, *args, **kwargs)\n",
    "        self.edit = None\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, CausalLMOutputWithPast]:\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        # decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs[0]\n",
    "\n",
    "        # TODO: maybe this should actually take the model dtype if I can get it\n",
    "        # Also, should I edit every token?\n",
    "        # torch.Size([1, 11, 4096])\n",
    "        # torch.Size([1, 1, 4096])\n",
    "        if self.edit is not None:\n",
    "            edit_norm = self.edit / torch.norm(self.edit)\n",
    "            # TODO: wait...do I want the final token or the first token?\n",
    "            projection = edit_norm * torch.dot(hidden_states[:,-1,:].squeeze(0), edit_norm)\n",
    "            print(projection)\n",
    "            print(projection.shape)\n",
    "            hidden_states = hidden_states - projection\n",
    "            # TODO: renormalize?\n",
    "\n",
    "        if self.config.pretraining_tp > 1:\n",
    "            lm_head_slices = self.lm_head.weight.split(self.vocab_size // self.config.pretraining_tp, dim=0)\n",
    "            logits = [F.linear(hidden_states, lm_head_slices[i]) for i in range(self.config.pretraining_tp)]\n",
    "            logits = torch.cat(logits, dim=-1)\n",
    "        else:\n",
    "            logits = self.lm_head(hidden_states)\n",
    "        logits = logits.float()\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Shift so that tokens < n predict n\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            # Flatten the tokens\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            shift_logits = shift_logits.view(-1, self.config.vocab_size)\n",
    "            shift_labels = shift_labels.view(-1)\n",
    "            # Enable model parallelism\n",
    "            shift_labels = shift_labels.to(shift_logits.device)\n",
    "            loss = loss_fct(shift_logits, shift_labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return (loss,) + output if loss is not None else output\n",
    "\n",
    "        return CausalLMOutputWithPast(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            past_key_values=outputs.past_key_values,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "    def generate_with_edit(self, inputs, edit=None, **generate_kwargs):\n",
    "        self.edit = edit\n",
    "        return self.generate(inputs, **generate_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"/net/projects/veitch/LLMs/\"\n",
    "MODEL = \"llama1-based-models/alpaca-7b\" # or llama2-based-models/llama2-hf/Llama-2-7b-chat-hf\n",
    "MODEL_PATH = MODEL_DIR + MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Clean this up\n",
    "# This cell is for doing ROME edits\n",
    "# ROME model and tokenizer\n",
    "# MODEL_NAME = \"gpt2-xl\"\n",
    "# model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eee2087e66a4c1bbeab6116b6694356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot copy out of meta tensor; no data!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/tnief/wiki-probes/train-notebook.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bg009.ds/home/tnief/wiki-probes/train-notebook.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# model = LlamaForCausalLM.from_pretrained(MODEL_PATH, low_cpu_mem_usage=True, torch_dtype=torch.float16, device_map=\"auto\").to(device)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bg009.ds/home/tnief/wiki-probes/train-notebook.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m EditableLlama\u001b[39m.\u001b[39;49mfrom_pretrained(MODEL_PATH, low_cpu_mem_usage\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, torch_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat16, device_map\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/transformers/modeling_utils.py:1900\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1896\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`.to` is not supported for `4-bit` or `8-bit` models. Please use the model as it is, since the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1897\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1898\u001b[0m     )\n\u001b[1;32m   1899\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1900\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mto(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 810 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Cannot copy out of meta tensor; no data!"
     ]
    }
   ],
   "source": [
    "# model = LlamaForCausalLM.from_pretrained(MODEL_PATH, low_cpu_mem_usage=True, torch_dtype=torch.float16, device_map=\"auto\").to(device)\n",
    "model = EditableLlama.from_pretrained(MODEL_PATH, low_cpu_mem_usage=True, torch_dtype=torch.float16, device_map=\"auto\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = \"title\" # choices are \"title\" and \"categories\"\n",
    "DATA_FOLDER = \"data/\"\n",
    "TRAIN_FILEPATH = DATA_FOLDER + \"train-12-articles.csv\"\n",
    "VAL_FILEPATH = DATA_FOLDER + \"val-12-articles.csv\"\n",
    "PROBE_TYPE = \"linear\" # choices are \"linear\" and \"mlp\"\n",
    "LAYER = None\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 4\n",
    "AGGREGATION = \"max\" # choices are \"max\" or \"mean\"\n",
    "PRINT_PROGRESS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, label_encoder_title, label_encoder_cats = scripts.get_hidden_states(TRAIN_FILEPATH, model, tokenizer, device)\n",
    "val_data, _, _ = scripts.get_hidden_states(VAL_FILEPATH, model, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use entire flattened activations use layer = None\n",
    "train_dataset = scripts.create_dataset(*train_data, layer=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = scripts.create_dataset(*val_data, layer=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.Xs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][5] loss: 1.716\n",
      "[Validation][5] loss: 0.972\n",
      "[Validation]5 accuracy: 0.667\n",
      "[Training][10] loss: 0.443\n",
      "[Validation][10] loss: 0.069\n",
      "[Validation]10 accuracy: 0.944\n",
      "[Training][15] loss: 0.000\n",
      "[Validation][15] loss: 0.053\n",
      "[Validation]15 accuracy: 0.917\n",
      "[Training][20] loss: 0.000\n",
      "[Validation][20] loss: 0.037\n",
      "[Validation]20 accuracy: 0.917\n",
      "[Training][25] loss: 0.000\n",
      "[Validation][25] loss: 0.029\n",
      "[Validation]25 accuracy: 0.917\n",
      "[Training][30] loss: 0.000\n",
      "[Validation][30] loss: 0.026\n",
      "[Validation]30 accuracy: 0.917\n",
      "[Training][35] loss: 0.000\n",
      "[Validation][35] loss: 0.021\n",
      "[Validation]35 accuracy: 0.917\n",
      "[Training][40] loss: 0.000\n",
      "[Validation][40] loss: 0.024\n",
      "[Validation]40 accuracy: 0.917\n",
      "[Training][45] loss: 1.040\n",
      "[Validation][45] loss: 0.725\n",
      "[Validation]45 accuracy: 0.806\n",
      "text:  a game that is played by two teams of eleven players using an oval-shaped ball. Players try to score points by passing or carrying the ball to their opponents' end of the field, or by kicking it over a bar fixed between two posts.\n",
      "labels:  American football\n",
      "predicted labels:  American football\n",
      "text:  review the procedures and the decisions in the trial court to make sure that the proceedings were fair and that the proper law was applied correctly\n",
      "labels:  Appellate court\n",
      "predicted labels:  Appellate court\n",
      "text:  the broad term for everything that goes into growing crops and raising animals, to provide food and materials that people can use and enjoy\n",
      "labels:  Agriculture\n",
      "predicted labels:  Agriculture\n",
      "text:  the preparation of animated cartoons\n",
      "labels:  Animation\n",
      "predicted labels:  Animation\n",
      "text:  the study of human biological and physiological characteristics and their evolution\n",
      "labels:  Anthropology\n",
      "predicted labels:  Anthropology\n",
      "text:  a cold-blooded vertebrate animal of a class that comprises the frogs, toads, newts, and salamanders. They are distinguished by having an aquatic gill-breathing larval stage followed (typically) by a terrestrial lung-breathing adult stage.\n",
      "labels:  Amphibian\n",
      "predicted labels:  Amphibian\n",
      "text:  an American game that is played between two teams of 11 players each and in which the ball is moved forward by running or passing\n",
      "labels:  American football\n",
      "predicted labels:  American football\n",
      "text:  the largest state owned by the United States of America and is part of the beautiful North American continent.\n",
      "labels:  Alaska\n",
      "predicted labels:  Alaska\n",
      "text:  theology dealing with the origin, nature, and destiny of human beings\n",
      "labels:  Anthropology\n",
      "predicted labels:  Anthropology\n",
      "text:  a medieval chemical science and speculative philosophy aiming to achieve the transmutation of the base metals into gold, the discovery of a universal cure for disease, and the discovery of a means of indefinitely prolonging life\n",
      "labels:  Alchemy\n",
      "predicted labels:  Alchemy\n",
      "text:  one of two US states not bordered by another state; Hawaii is the other.\n",
      "labels:  Alaska\n",
      "predicted labels:  Alaska\n",
      "text:  or farming, is the simplification of nature's food webs and the rechanneling of energy for human planting and animal consumption\n",
      "labels:  Agriculture\n",
      "predicted labels:  Agriculture\n",
      "text:  the largest state in the union and; one-fifth the size of the lower 48 states\n",
      "labels:  Alaska\n",
      "predicted labels:  Alaska\n",
      "text:  a simple, nonflowering, and typically aquatic plant of a large group that includes the seaweeds and many single-celled forms. Algae contain chlorophyll but lack true stems, roots, leaves, and vascular tissue.\n",
      "labels:  Algae\n",
      "predicted labels:  Algae\n",
      "text:  the technique of photographing successive drawings or positions of puppets or models to create an illusion of movement when the movie is shown as a sequence.\n",
      "labels:  Animation\n",
      "predicted labels:  Animation\n",
      "text:  the organization of society on the basis of voluntary cooperation, without political institutions or hierarchical government\n",
      "labels:  Anarchism\n",
      "predicted labels:  Anarchism\n",
      "text:  a usually indoor court game between two teams of usually five players each who score by tossing an inflated ball through a raised goal\n",
      "labels:  Basketball\n",
      "predicted labels:  Basketball\n",
      "text:  studies celestial objects and phenomena in the universe. They explore and investigate various aspects of the cosmos, including stars, planets, galaxies, asteroids, comets, and other celestial bodies\n",
      "labels:  Astronomer\n",
      "predicted labels:  Astronomer\n",
      "text:  the manipulation of electronic images by means of a computer in order to create moving images.\n",
      "labels:  Animation\n",
      "predicted labels:  Animation\n",
      "text:  a utopian society of individuals who enjoy complete freedom without government\n",
      "labels:  Anarchism\n",
      "predicted labels:  Anarchism\n",
      "text:  the medieval forerunner of chemistry, based on the supposed transformation of matter. It was concerned particularly with attempts to convert base metals into gold or to find a universal elixir.\n",
      "labels:  Alchemy\n",
      "predicted labels:  Alchemy\n",
      "text:  a game played between two teams of five players in which goals are scored by throwing a ball through a netted hoop fixed above each end of the court\n",
      "labels:  Basketball\n",
      "predicted labels:  Basketball\n",
      "text:  a form of speculative thought that, among other aims, tried to transform base metals such as lead or copper into silver or gold and to discover a cure for disease and a way of extending life\n",
      "labels:  Alchemy\n",
      "predicted labels:  Alchemy\n",
      "text:  They use telescopes, both on the ground and in space, to observe and collect data from distant objects. They analyze the light emitted or reflected by celestial bodies to determine their properties, such as their composition, temperature, distance, and motion\n",
      "labels:  Astronomer\n",
      "predicted labels:  Astronomer\n",
      "text:  small vertebrates that need water, or a moist environment, to survive. The species in this group include frogs, toads, salamanders, and newts. All can breathe and absorb water through their very thin skin.\n",
      "labels:  Amphibian\n",
      "predicted labels:  Amphibian\n",
      "text:  cold-blooded vertebrates (vertebrates have backbones) that don’t have scales. They live part of their lives in water and part on land.\n",
      "labels:  Amphibian\n",
      "predicted labels:  Amphibian\n",
      "text:  a state of disorder due to absence or nonrecognition of authority or other controlling systems\n",
      "labels:  Anarchism\n",
      "predicted labels:  Anthropology\n",
      "text:  a form of team game played in North America with an oval ball on a field marked out as a gridiron\n",
      "labels:  American football\n",
      "predicted labels:  American football\n",
      "text:  members of a group of predominantly aquatic photosynthetic organisms of the kingdom Protista\n",
      "labels:  Algae\n",
      "predicted labels:  Algae\n",
      "text:  The objective of the game is to throw (shoot) a ball through the top of a circular band (referred to as the rim) that has cord hanging around its circumference (with both being named the basket), which is itself attached to a backboard\n",
      "labels:  Basketball\n",
      "predicted labels:  Basketball\n",
      "text:  Persons or entities such as corporations that experience an unsuccessful outcome in a trial-level or other lower courts may file an appeal with an appellate court to have the decision reviewed\n",
      "labels:  Appellate court\n",
      "predicted labels:  Appellate court\n",
      "text:  the part of the American judicial system that is responsible for hearing and reviewing appeals from legal cases that have already been heard in a trial-level or other lower court\n",
      "labels:  Appellate court\n",
      "predicted labels:  Appellate court\n",
      "text:  scientists who study the Universe and the objects within it\n",
      "labels:  Astronomer\n",
      "predicted labels:  Anthropology\n",
      "text:  the science or practice of farming, including cultivation of the soil for the growing of crops and the rearing of animals to provide food, wool, and other products.\n",
      "labels:  Agriculture\n",
      "predicted labels:  Agriculture\n",
      "text:  the study of human societies and cultures and their development\n",
      "labels:  Anthropology\n",
      "predicted labels:  Anthropology\n",
      "text:  a diverse group of aquatic organisms that have the ability to conduct photosynthesis\n",
      "labels:  Algae\n",
      "predicted labels:  Algae\n",
      "[Training][50] loss: 0.000\n",
      "[Validation][50] loss: 0.085\n",
      "[Validation]50 accuracy: 0.944\n"
     ]
    }
   ],
   "source": [
    "probe, _ = scripts.train_handler(train_dataset, val_dataset, label_encoder_title, probe_type=PROBE_TYPE, labels=LABELS, batch_size=BATCH_SIZE, epochs=EPOCHS, print_progress=PRINT_PROGRESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Editing With Linear Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 4096])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe.fc1.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Agriculture', 'Alaska', 'Alchemy', 'Algae', 'American football',\n",
       "       'Amphibian', 'Anarchism', 'Animation', 'Anthropology',\n",
       "       'Appellate court', 'Astronomer', 'Basketball'], dtype='<U17')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder_title.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0380, 0.0801, 0.0040,  ..., 0.0858, 0.0228, 0.0204])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe.fc1.weight.data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"I hate authority and my favorite form of government is\"\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').input_ids.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_idx = 6\n",
    "edit = 5 * torch.rand(4096) # random noise\n",
    "edit = None\n",
    "edit = probe.fc1.weight.data[probe_idx]\n",
    "\n",
    "edit = edit.half().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size, expected tensor [45056] and src [4096] to have the same number of elements, but got 45056 and 4096 elements respectively",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/tnief/wiki-probes/train-notebook.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bg009.ds/home/tnief/wiki-probes/train-notebook.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate_with_edit(input_ids, edit\u001b[39m=\u001b[39;49medit, max_length\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, num_return_sequences\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, output_hidden_states\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bg009.ds/home/tnief/wiki-probes/train-notebook.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m generated_text \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mdecode(output[\u001b[39m0\u001b[39m], skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m/home/tnief/wiki-probes/train-notebook.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bg009.ds/home/tnief/wiki-probes/train-notebook.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=97'>98</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_with_edit\u001b[39m(\u001b[39mself\u001b[39m, inputs, edit\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgenerate_kwargs):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bg009.ds/home/tnief/wiki-probes/train-notebook.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=98'>99</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medit \u001b[39m=\u001b[39m edit\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bg009.ds/home/tnief/wiki-probes/train-notebook.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=99'>100</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgenerate_kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/transformers/generation/utils.py:1538\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1533\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnum_return_sequences has to be 1 when doing greedy search, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1534\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut is \u001b[39m\u001b[39m{\u001b[39;00mgeneration_config\u001b[39m.\u001b[39mnum_return_sequences\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1535\u001b[0m         )\n\u001b[1;32m   1537\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1538\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[1;32m   1539\u001b[0m         input_ids,\n\u001b[1;32m   1540\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1541\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1542\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   1543\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   1544\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   1545\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1546\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1547\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[1;32m   1548\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1549\u001b[0m     )\n\u001b[1;32m   1551\u001b[0m \u001b[39melif\u001b[39;00m is_contrastive_search_gen_mode:\n\u001b[1;32m   1552\u001b[0m     \u001b[39mif\u001b[39;00m generation_config\u001b[39m.\u001b[39mnum_return_sequences \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/transformers/generation/utils.py:2362\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2359\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2361\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2362\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2363\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2364\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2365\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2366\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2367\u001b[0m )\n\u001b[1;32m   2369\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2370\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/tnief/wiki-probes/train-notebook.ipynb Cell 22\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bg009.ds/home/tnief/wiki-probes/train-notebook.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bg009.ds/home/tnief/wiki-probes/train-notebook.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     edit_norm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medit \u001b[39m/\u001b[39m torch\u001b[39m.\u001b[39mnorm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39medit)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bg009.ds/home/tnief/wiki-probes/train-notebook.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m     projection \u001b[39m=\u001b[39m edit_norm \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39;49mdot(hidden_states\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), edit_norm)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bg009.ds/home/tnief/wiki-probes/train-notebook.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m     \u001b[39mprint\u001b[39m(projection)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bg009.ds/home/tnief/wiki-probes/train-notebook.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39mprint\u001b[39m(projection\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected tensor [45056] and src [4096] to have the same number of elements, but got 45056 and 4096 elements respectively"
     ]
    }
   ],
   "source": [
    "output = model.generate_with_edit(input_ids, edit=edit, max_length=50, num_return_sequences=1, output_hidden_states=False)\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text\n",
    "\n",
    "# Notes:\n",
    "# If you just add the probe weights multiplied by 100, you get the probe word repeated ie \"animation\", \"anth\", \"Alaska\"\n",
    "# Interestingly, anarchy seems to give \"libert\" (as in \"liberty\") so these are a similar direction\n",
    "# Subtracting gives \"Dictator\"...for Alaska\n",
    "# Gives \"Science\" for \"Anarchy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set something up to classify the output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wiki-probes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
