{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle gpu leakage issue on DSI cluster\n",
    "# ideally we shouldn't have to do this but leaving it for now in case the issue pops up again\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM, LlamaTokenizer\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "\n",
    "import scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm GPUs are working properly and set default device explicitly\n",
    "device = \"cuda:0\"\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"/net/projects/veitch/LLMs/\"\n",
    "MODEL = \"llama1-based-models/alpaca-7b\" # or llama2-based-models/llama2-hf/Llama-2-7b-chat-hf\n",
    "MODEL_PATH = MODEL_DIR + MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Clean this up\n",
    "\n",
    "# This cell is for doing ROME edits\n",
    "# ROME model and tokenizer\n",
    "# MODEL_NAME = \"gpt2-xl\"\n",
    "# model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776ed282d94b472d937cfa33aab5c462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = LlamaForCausalLM.from_pretrained(MODEL_PATH, low_cpu_mem_usage=True, torch_dtype=torch.float16, device_map=\"auto\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = \"title\" # choices are \"title\" and \"categories\"\n",
    "DATA_FOLDER = \"data/\"\n",
    "TRAIN_FILEPATH = DATA_FOLDER + \"train-12-articles.csv\"\n",
    "VAL_FILEPATH = DATA_FOLDER + \"val-12-articles.csv\"\n",
    "PROBE_TYPE = \"linear\" # choices are \"linear\" and \"mlp\"\n",
    "LAYER = None\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 4\n",
    "AGGREGATION = \"max\" # choices are \"max\" or \"mean\"\n",
    "PRINT_PROGRESS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, label_encoder_title, label_encoder_cats = scripts.get_hidden_states(TRAIN_FILEPATH, model, tokenizer, device)\n",
    "val_data, _, _ = scripts.get_hidden_states(VAL_FILEPATH, model, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use entire flattened activations use layer = None\n",
    "train_dataset = scripts.create_dataset(*train_data, layer=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = scripts.create_dataset(*val_data, layer=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.Xs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][5] loss: 1.459\n",
      "[Validation][5] loss: 0.275\n",
      "[Validation]5 accuracy: 0.833\n",
      "[Training][10] loss: 1.276\n",
      "[Validation][10] loss: 0.412\n",
      "[Validation]10 accuracy: 0.778\n",
      "[Training][15] loss: 0.641\n",
      "[Validation][15] loss: 0.447\n",
      "[Validation]15 accuracy: 0.806\n",
      "[Training][20] loss: 0.033\n",
      "[Validation][20] loss: 0.099\n",
      "[Validation]20 accuracy: 0.917\n",
      "[Training][25] loss: 0.000\n",
      "[Validation][25] loss: 0.098\n",
      "[Validation]25 accuracy: 0.917\n",
      "[Training][30] loss: 0.000\n",
      "[Validation][30] loss: 0.091\n",
      "[Validation]30 accuracy: 0.917\n",
      "[Training][35] loss: 0.000\n",
      "[Validation][35] loss: 0.075\n",
      "[Validation]35 accuracy: 0.917\n",
      "[Training][40] loss: 0.000\n",
      "[Validation][40] loss: 0.068\n",
      "[Validation]40 accuracy: 0.917\n",
      "[Training][45] loss: 0.000\n",
      "[Validation][45] loss: 0.063\n",
      "[Validation]45 accuracy: 0.944\n",
      "text:  the part of the American judicial system that is responsible for hearing and reviewing appeals from legal cases that have already been heard in a trial-level or other lower court\n",
      "labels:  Appellate court\n",
      "predicted labels:  Appellate court\n",
      "text:  an American game that is played between two teams of 11 players each and in which the ball is moved forward by running or passing\n",
      "labels:  American football\n",
      "predicted labels:  Basketball\n",
      "text:  the largest state owned by the United States of America and is part of the beautiful North American continent.\n",
      "labels:  Alaska\n",
      "predicted labels:  Alaska\n",
      "text:  Persons or entities such as corporations that experience an unsuccessful outcome in a trial-level or other lower courts may file an appeal with an appellate court to have the decision reviewed\n",
      "labels:  Appellate court\n",
      "predicted labels:  Appellate court\n",
      "text:  the preparation of animated cartoons\n",
      "labels:  Animation\n",
      "predicted labels:  Animation\n",
      "text:  members of a group of predominantly aquatic photosynthetic organisms of the kingdom Protista\n",
      "labels:  Algae\n",
      "predicted labels:  Algae\n",
      "text:  scientists who study the Universe and the objects within it\n",
      "labels:  Astronomer\n",
      "predicted labels:  Astronomer\n",
      "text:  one of two US states not bordered by another state; Hawaii is the other.\n",
      "labels:  Alaska\n",
      "predicted labels:  Alaska\n",
      "text:  or farming, is the simplification of nature's food webs and the rechanneling of energy for human planting and animal consumption\n",
      "labels:  Agriculture\n",
      "predicted labels:  Agriculture\n",
      "text:  a usually indoor court game between two teams of usually five players each who score by tossing an inflated ball through a raised goal\n",
      "labels:  Basketball\n",
      "predicted labels:  Basketball\n",
      "text:  a diverse group of aquatic organisms that have the ability to conduct photosynthesis\n",
      "labels:  Algae\n",
      "predicted labels:  Algae\n",
      "text:  a utopian society of individuals who enjoy complete freedom without government\n",
      "labels:  Anarchism\n",
      "predicted labels:  Anarchism\n",
      "text:  a game played between two teams of five players in which goals are scored by throwing a ball through a netted hoop fixed above each end of the court\n",
      "labels:  Basketball\n",
      "predicted labels:  Basketball\n",
      "text:  a medieval chemical science and speculative philosophy aiming to achieve the transmutation of the base metals into gold, the discovery of a universal cure for disease, and the discovery of a means of indefinitely prolonging life\n",
      "labels:  Alchemy\n",
      "predicted labels:  Alchemy\n",
      "text:  review the procedures and the decisions in the trial court to make sure that the proceedings were fair and that the proper law was applied correctly\n",
      "labels:  Appellate court\n",
      "predicted labels:  Appellate court\n",
      "text:  the medieval forerunner of chemistry, based on the supposed transformation of matter. It was concerned particularly with attempts to convert base metals into gold or to find a universal elixir.\n",
      "labels:  Alchemy\n",
      "predicted labels:  Alchemy\n",
      "text:  a simple, nonflowering, and typically aquatic plant of a large group that includes the seaweeds and many single-celled forms. Algae contain chlorophyll but lack true stems, roots, leaves, and vascular tissue.\n",
      "labels:  Algae\n",
      "predicted labels:  Algae\n",
      "text:  a form of team game played in North America with an oval ball on a field marked out as a gridiron\n",
      "labels:  American football\n",
      "predicted labels:  American football\n",
      "text:  a game that is played by two teams of eleven players using an oval-shaped ball. Players try to score points by passing or carrying the ball to their opponents' end of the field, or by kicking it over a bar fixed between two posts.\n",
      "labels:  American football\n",
      "predicted labels:  Basketball\n",
      "text:  a state of disorder due to absence or nonrecognition of authority or other controlling systems\n",
      "labels:  Anarchism\n",
      "predicted labels:  Anarchism\n",
      "text:  theology dealing with the origin, nature, and destiny of human beings\n",
      "labels:  Anthropology\n",
      "predicted labels:  Anthropology\n",
      "text:  a form of speculative thought that, among other aims, tried to transform base metals such as lead or copper into silver or gold and to discover a cure for disease and a way of extending life\n",
      "labels:  Alchemy\n",
      "predicted labels:  Alchemy\n",
      "text:  the technique of photographing successive drawings or positions of puppets or models to create an illusion of movement when the movie is shown as a sequence.\n",
      "labels:  Animation\n",
      "predicted labels:  Animation\n",
      "text:  The objective of the game is to throw (shoot) a ball through the top of a circular band (referred to as the rim) that has cord hanging around its circumference (with both being named the basket), which is itself attached to a backboard\n",
      "labels:  Basketball\n",
      "predicted labels:  Basketball\n",
      "text:  the study of human biological and physiological characteristics and their evolution\n",
      "labels:  Anthropology\n",
      "predicted labels:  Anthropology\n",
      "text:  a cold-blooded vertebrate animal of a class that comprises the frogs, toads, newts, and salamanders. They are distinguished by having an aquatic gill-breathing larval stage followed (typically) by a terrestrial lung-breathing adult stage.\n",
      "labels:  Amphibian\n",
      "predicted labels:  Amphibian\n",
      "text:  cold-blooded vertebrates (vertebrates have backbones) that don’t have scales. They live part of their lives in water and part on land.\n",
      "labels:  Amphibian\n",
      "predicted labels:  Amphibian\n",
      "text:  studies celestial objects and phenomena in the universe. They explore and investigate various aspects of the cosmos, including stars, planets, galaxies, asteroids, comets, and other celestial bodies\n",
      "labels:  Astronomer\n",
      "predicted labels:  Astronomer\n",
      "text:  the organization of society on the basis of voluntary cooperation, without political institutions or hierarchical government\n",
      "labels:  Anarchism\n",
      "predicted labels:  Anarchism\n",
      "text:  They use telescopes, both on the ground and in space, to observe and collect data from distant objects. They analyze the light emitted or reflected by celestial bodies to determine their properties, such as their composition, temperature, distance, and motion\n",
      "labels:  Astronomer\n",
      "predicted labels:  Astronomer\n",
      "text:  the study of human societies and cultures and their development\n",
      "labels:  Anthropology\n",
      "predicted labels:  Anthropology\n",
      "text:  the science or practice of farming, including cultivation of the soil for the growing of crops and the rearing of animals to provide food, wool, and other products.\n",
      "labels:  Agriculture\n",
      "predicted labels:  Agriculture\n",
      "text:  the broad term for everything that goes into growing crops and raising animals, to provide food and materials that people can use and enjoy\n",
      "labels:  Agriculture\n",
      "predicted labels:  Agriculture\n",
      "text:  the manipulation of electronic images by means of a computer in order to create moving images.\n",
      "labels:  Animation\n",
      "predicted labels:  Animation\n",
      "text:  the largest state in the union and; one-fifth the size of the lower 48 states\n",
      "labels:  Alaska\n",
      "predicted labels:  Alaska\n",
      "text:  small vertebrates that need water, or a moist environment, to survive. The species in this group include frogs, toads, salamanders, and newts. All can breathe and absorb water through their very thin skin.\n",
      "labels:  Amphibian\n",
      "predicted labels:  Amphibian\n",
      "[Training][50] loss: 0.000\n",
      "[Validation][50] loss: 0.059\n",
      "[Validation]50 accuracy: 0.944\n"
     ]
    }
   ],
   "source": [
    "probe, _ = scripts.train_handler(train_dataset, val_dataset, label_encoder_title, probe_type=PROBE_TYPE, labels=LABELS, batch_size=BATCH_SIZE, epochs=EPOCHS, print_progress=PRINT_PROGRESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Editing With Linear Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 4096])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe.fc1.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Agriculture', 'Alaska', 'Alchemy', 'Algae', 'American football',\n",
       "       'Amphibian', 'Anarchism', 'Animation', 'Anthropology',\n",
       "       'Appellate court', 'Astronomer', 'Basketball'], dtype='<U17')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder_title.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"I hate authority and my favorite form of government is\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').input_ids.to(device)\n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 4096])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(input_ids, output_hidden_states=True)\n",
    "output.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 32001])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model.lm_head(output.hidden_states[-1])\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32001) must match the size of tensor b (4096) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/tnief/wiki-probes/train-notebook.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bg007.ds/home/tnief/wiki-probes/train-notebook.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m logits_mod \u001b[39m=\u001b[39m logits[:,\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,:] \u001b[39m-\u001b[39;49m probe\u001b[39m.\u001b[39;49mfc1\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39;49mdata[\u001b[39m6\u001b[39;49m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32001) must match the size of tensor b (4096) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "logits_mod = logits[:,-1,:] - probe.fc1.weight.data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token = logits[:,-1,:].argmax(-1)\n",
    "next_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'an'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text = tokenizer.decode(next_token, skip_special_tokens=True)\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try modifying the final layer of the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.31.0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n"
     ]
    }
   ],
   "source": [
    "output = editable_model.generate(input_ids, max_length=50, num_return_sequences=1, output_hidden_states=True) # default search strategy is greedy\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I hate authority and my favorite form of government is anarchy.\\nI'm a big fan of the idea of a free society, but I'm not sure that anarchy is the way to get there.\\nI think that an\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Inheriting Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EditableLlama(LlamaForCausalLM):\n",
    "    def __init__(self, config, edit=None, *args, **kwargs):\n",
    "        super().__init__(config, *args, **kwargs)\n",
    "        self.edit = edit\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, CausalLMOutputWithPast]:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "                Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n",
    "                config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored\n",
    "                (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`.\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        Example:\n",
    "\n",
    "        ```python\n",
    "        >>> from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "\n",
    "        >>> model = LlamaForCausalLM.from_pretrained(PATH_TO_CONVERTED_WEIGHTS)\n",
    "        >>> tokenizer = AutoTokenizer.from_pretrained(PATH_TO_CONVERTED_TOKENIZER)\n",
    "\n",
    "        >>> prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
    "        >>> inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "        >>> # Generate\n",
    "        >>> generate_ids = model.generate(inputs.input_ids, max_length=30)\n",
    "        >>> tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "        \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\n",
    "        ```\"\"\"\n",
    "\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        # decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs[0]\n",
    "        print(hidden_states.shape)\n",
    "        # TODO: Insert model edit here\n",
    "        # torch.Size([1, 11, 4096])\n",
    "        # torch.Size([1, 1, 4096])\n",
    "\n",
    "        if self.config.pretraining_tp > 1:\n",
    "            lm_head_slices = self.lm_head.weight.split(self.vocab_size // self.config.pretraining_tp, dim=0)\n",
    "            logits = [F.linear(hidden_states, lm_head_slices[i]) for i in range(self.config.pretraining_tp)]\n",
    "            logits = torch.cat(logits, dim=-1)\n",
    "        else:\n",
    "            logits = self.lm_head(hidden_states)\n",
    "        logits = logits.float()\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Shift so that tokens < n predict n\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            # Flatten the tokens\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            shift_logits = shift_logits.view(-1, self.config.vocab_size)\n",
    "            shift_labels = shift_labels.view(-1)\n",
    "            # Enable model parallelism\n",
    "            shift_labels = shift_labels.to(shift_logits.device)\n",
    "            loss = loss_fct(shift_logits, shift_labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return (loss,) + output if loss is not None else output\n",
    "\n",
    "        return CausalLMOutputWithPast(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            past_key_values=outputs.past_key_values,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /net/projects/veitch/LLMs/llama1-based-models/alpaca-7b/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"/net/scratch/reber/alpaca-7b\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.31.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32001\n",
      "}\n",
      "\n",
      "loading weights file /net/projects/veitch/LLMs/llama1-based-models/alpaca-7b/pytorch_model.bin.index.json\n",
      "Instantiating EditableLlama model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.31.0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a3f6bb21014cacbb3c09579cf90ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing EditableLlama.\n",
      "\n",
      "All the weights of EditableLlama were initialized from the model checkpoint at /net/projects/veitch/LLMs/llama1-based-models/alpaca-7b.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use EditableLlama for predictions without further training.\n",
      "loading configuration file /net/projects/veitch/LLMs/llama1-based-models/alpaca-7b/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.31.0\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "editable_model = EditableLlama.from_pretrained(MODEL_PATH, low_cpu_mem_usage=True, torch_dtype=torch.float16, device_map=\"auto\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wiki-probes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
