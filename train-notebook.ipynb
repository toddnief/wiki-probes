{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle gpu leakage issue on DSI cluster\n",
    "# ideally we shouldn't have to do this but leaving it for now in case the issue pops up again\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM, LlamaTokenizer\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "\n",
    "import scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm GPUs are working properly and set default device explicitly\n",
    "device = \"cuda:0\"\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"/net/projects/veitch/LLMs/\"\n",
    "MODEL = \"llama1-based-models/alpaca-7b\" # or llama2-based-models/llama2-hf/Llama-2-7b-chat-hf\n",
    "MODEL_PATH = MODEL_DIR + MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Clean this up\n",
    "\n",
    "# This cell is for doing ROME edits\n",
    "# ROME model and tokenizer\n",
    "# MODEL_NAME = \"gpt2-xl\"\n",
    "# model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92dc055024a34a7d9ed0d94c3cce626c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tnief/wiki-probes/train-notebook.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bi001.ds/home/tnief/wiki-probes/train-notebook.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m LlamaTokenizer\u001b[39m.\u001b[39mfrom_pretrained(MODEL_PATH)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bi001.ds/home/tnief/wiki-probes/train-notebook.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m LlamaForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(MODEL_PATH, low_cpu_mem_usage\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, torch_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat16, device_map\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/transformers/modeling_utils.py:2903\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m     \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2894\u001b[0m         torch\u001b[39m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   2896\u001b[0m     (\n\u001b[1;32m   2897\u001b[0m         model,\n\u001b[1;32m   2898\u001b[0m         missing_keys,\n\u001b[1;32m   2899\u001b[0m         unexpected_keys,\n\u001b[1;32m   2900\u001b[0m         mismatched_keys,\n\u001b[1;32m   2901\u001b[0m         offload_index,\n\u001b[1;32m   2902\u001b[0m         error_msgs,\n\u001b[0;32m-> 2903\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_load_pretrained_model(\n\u001b[1;32m   2904\u001b[0m         model,\n\u001b[1;32m   2905\u001b[0m         state_dict,\n\u001b[1;32m   2906\u001b[0m         loaded_state_dict_keys,  \u001b[39m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   2907\u001b[0m         resolved_archive_file,\n\u001b[1;32m   2908\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   2909\u001b[0m         ignore_mismatched_sizes\u001b[39m=\u001b[39;49mignore_mismatched_sizes,\n\u001b[1;32m   2910\u001b[0m         sharded_metadata\u001b[39m=\u001b[39;49msharded_metadata,\n\u001b[1;32m   2911\u001b[0m         _fast_init\u001b[39m=\u001b[39;49m_fast_init,\n\u001b[1;32m   2912\u001b[0m         low_cpu_mem_usage\u001b[39m=\u001b[39;49mlow_cpu_mem_usage,\n\u001b[1;32m   2913\u001b[0m         device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m   2914\u001b[0m         offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m   2915\u001b[0m         offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[1;32m   2916\u001b[0m         dtype\u001b[39m=\u001b[39;49mtorch_dtype,\n\u001b[1;32m   2917\u001b[0m         is_quantized\u001b[39m=\u001b[39;49m(load_in_8bit \u001b[39mor\u001b[39;49;00m load_in_4bit),\n\u001b[1;32m   2918\u001b[0m         keep_in_fp32_modules\u001b[39m=\u001b[39;49mkeep_in_fp32_modules,\n\u001b[1;32m   2919\u001b[0m     )\n\u001b[1;32m   2921\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_4bit \u001b[39m=\u001b[39m load_in_4bit\n\u001b[1;32m   2922\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_8bit \u001b[39m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/transformers/modeling_utils.py:3246\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3244\u001b[0m \u001b[39mif\u001b[39;00m shard_file \u001b[39min\u001b[39;00m disk_only_shard_files:\n\u001b[1;32m   3245\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m-> 3246\u001b[0m state_dict \u001b[39m=\u001b[39m load_state_dict(shard_file)\n\u001b[1;32m   3248\u001b[0m \u001b[39m# Mistmatched keys contains tuples key/shape1/shape2 of weights in the checkpoint that have a shape not\u001b[39;00m\n\u001b[1;32m   3249\u001b[0m \u001b[39m# matching the weights in the model.\u001b[39;00m\n\u001b[1;32m   3250\u001b[0m mismatched_keys \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m _find_mismatched_keys(\n\u001b[1;32m   3251\u001b[0m     state_dict,\n\u001b[1;32m   3252\u001b[0m     model_state_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3256\u001b[0m     ignore_mismatched_sizes,\n\u001b[1;32m   3257\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/transformers/modeling_utils.py:460\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[39mreturn\u001b[39;00m safe_load_file(checkpoint_file)\n\u001b[1;32m    459\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mload(checkpoint_file, map_location\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    461\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    462\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/torch/serialization.py:1014\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1013\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1014\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile,\n\u001b[1;32m   1015\u001b[0m                      map_location,\n\u001b[1;32m   1016\u001b[0m                      pickle_module,\n\u001b[1;32m   1017\u001b[0m                      overall_storage\u001b[39m=\u001b[39;49moverall_storage,\n\u001b[1;32m   1018\u001b[0m                      \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m   1019\u001b[0m \u001b[39mif\u001b[39;00m mmap:\n\u001b[1;32m   1020\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmmap can only be used with files saved with \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1021\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1022\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/torch/serialization.py:1422\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1420\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1421\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1422\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1424\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1425\u001b[0m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1426\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtorch.load.metadata\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mserialization_id\u001b[39m\u001b[39m\"\u001b[39m: zip_file\u001b[39m.\u001b[39mserialization_id()}\n\u001b[1;32m   1427\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/torch/serialization.py:1392\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1391\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1392\u001b[0m     typed_storage \u001b[39m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1394\u001b[0m \u001b[39mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/wiki-probes/lib/python3.8/site-packages/torch/serialization.py:1357\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     storage \u001b[39m=\u001b[39m overall_storage[storage_offset:storage_offset \u001b[39m+\u001b[39m numel]\n\u001b[1;32m   1356\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1357\u001b[0m     storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39;49mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39;49mUntypedStorage)\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_untyped_storage\n\u001b[1;32m   1358\u001b[0m \u001b[39m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m \u001b[39mif\u001b[39;00m byteorderdata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = LlamaForCausalLM.from_pretrained(MODEL_PATH, low_cpu_mem_usage=True, torch_dtype=torch.float16, device_map=\"auto\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = \"title\" # choices are \"title\" and \"categories\"\n",
    "DATA_FOLDER = \"data/\"\n",
    "TRAIN_FILEPATH = DATA_FOLDER + \"train-12-articles.csv\"\n",
    "VAL_FILEPATH = DATA_FOLDER + \"val-12-articles.csv\"\n",
    "PROBE_TYPE = \"linear\" # choices are \"linear\" and \"mlp\"\n",
    "LAYER = None\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 4\n",
    "AGGREGATION = \"max\" # choices are \"max\" or \"mean\"\n",
    "PRINT_PROGRESS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, label_encoder_title, label_encoder_cats = scripts.get_hidden_states(TRAIN_FILEPATH, model, tokenizer, device)\n",
    "val_data, _, _ = scripts.get_hidden_states(VAL_FILEPATH, model, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use entire flattened activations use layer = None\n",
    "train_dataset = scripts.create_dataset(*train_data, layer=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = scripts.create_dataset(*val_data, layer=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.Xs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][5] loss: 1.459\n",
      "[Validation][5] loss: 0.275\n",
      "[Validation]5 accuracy: 0.833\n",
      "[Training][10] loss: 1.276\n",
      "[Validation][10] loss: 0.412\n",
      "[Validation]10 accuracy: 0.778\n",
      "[Training][15] loss: 0.641\n",
      "[Validation][15] loss: 0.447\n",
      "[Validation]15 accuracy: 0.806\n",
      "[Training][20] loss: 0.033\n",
      "[Validation][20] loss: 0.099\n",
      "[Validation]20 accuracy: 0.917\n",
      "[Training][25] loss: 0.000\n",
      "[Validation][25] loss: 0.098\n",
      "[Validation]25 accuracy: 0.917\n",
      "[Training][30] loss: 0.000\n",
      "[Validation][30] loss: 0.091\n",
      "[Validation]30 accuracy: 0.917\n",
      "[Training][35] loss: 0.000\n",
      "[Validation][35] loss: 0.075\n",
      "[Validation]35 accuracy: 0.917\n",
      "[Training][40] loss: 0.000\n",
      "[Validation][40] loss: 0.068\n",
      "[Validation]40 accuracy: 0.917\n",
      "[Training][45] loss: 0.000\n",
      "[Validation][45] loss: 0.063\n",
      "[Validation]45 accuracy: 0.944\n",
      "text:  the part of the American judicial system that is responsible for hearing and reviewing appeals from legal cases that have already been heard in a trial-level or other lower court\n",
      "labels:  Appellate court\n",
      "predicted labels:  Appellate court\n",
      "text:  an American game that is played between two teams of 11 players each and in which the ball is moved forward by running or passing\n",
      "labels:  American football\n",
      "predicted labels:  Basketball\n",
      "text:  the largest state owned by the United States of America and is part of the beautiful North American continent.\n",
      "labels:  Alaska\n",
      "predicted labels:  Alaska\n",
      "text:  Persons or entities such as corporations that experience an unsuccessful outcome in a trial-level or other lower courts may file an appeal with an appellate court to have the decision reviewed\n",
      "labels:  Appellate court\n",
      "predicted labels:  Appellate court\n",
      "text:  the preparation of animated cartoons\n",
      "labels:  Animation\n",
      "predicted labels:  Animation\n",
      "text:  members of a group of predominantly aquatic photosynthetic organisms of the kingdom Protista\n",
      "labels:  Algae\n",
      "predicted labels:  Algae\n",
      "text:  scientists who study the Universe and the objects within it\n",
      "labels:  Astronomer\n",
      "predicted labels:  Astronomer\n",
      "text:  one of two US states not bordered by another state; Hawaii is the other.\n",
      "labels:  Alaska\n",
      "predicted labels:  Alaska\n",
      "text:  or farming, is the simplification of nature's food webs and the rechanneling of energy for human planting and animal consumption\n",
      "labels:  Agriculture\n",
      "predicted labels:  Agriculture\n",
      "text:  a usually indoor court game between two teams of usually five players each who score by tossing an inflated ball through a raised goal\n",
      "labels:  Basketball\n",
      "predicted labels:  Basketball\n",
      "text:  a diverse group of aquatic organisms that have the ability to conduct photosynthesis\n",
      "labels:  Algae\n",
      "predicted labels:  Algae\n",
      "text:  a utopian society of individuals who enjoy complete freedom without government\n",
      "labels:  Anarchism\n",
      "predicted labels:  Anarchism\n",
      "text:  a game played between two teams of five players in which goals are scored by throwing a ball through a netted hoop fixed above each end of the court\n",
      "labels:  Basketball\n",
      "predicted labels:  Basketball\n",
      "text:  a medieval chemical science and speculative philosophy aiming to achieve the transmutation of the base metals into gold, the discovery of a universal cure for disease, and the discovery of a means of indefinitely prolonging life\n",
      "labels:  Alchemy\n",
      "predicted labels:  Alchemy\n",
      "text:  review the procedures and the decisions in the trial court to make sure that the proceedings were fair and that the proper law was applied correctly\n",
      "labels:  Appellate court\n",
      "predicted labels:  Appellate court\n",
      "text:  the medieval forerunner of chemistry, based on the supposed transformation of matter. It was concerned particularly with attempts to convert base metals into gold or to find a universal elixir.\n",
      "labels:  Alchemy\n",
      "predicted labels:  Alchemy\n",
      "text:  a simple, nonflowering, and typically aquatic plant of a large group that includes the seaweeds and many single-celled forms. Algae contain chlorophyll but lack true stems, roots, leaves, and vascular tissue.\n",
      "labels:  Algae\n",
      "predicted labels:  Algae\n",
      "text:  a form of team game played in North America with an oval ball on a field marked out as a gridiron\n",
      "labels:  American football\n",
      "predicted labels:  American football\n",
      "text:  a game that is played by two teams of eleven players using an oval-shaped ball. Players try to score points by passing or carrying the ball to their opponents' end of the field, or by kicking it over a bar fixed between two posts.\n",
      "labels:  American football\n",
      "predicted labels:  Basketball\n",
      "text:  a state of disorder due to absence or nonrecognition of authority or other controlling systems\n",
      "labels:  Anarchism\n",
      "predicted labels:  Anarchism\n",
      "text:  theology dealing with the origin, nature, and destiny of human beings\n",
      "labels:  Anthropology\n",
      "predicted labels:  Anthropology\n",
      "text:  a form of speculative thought that, among other aims, tried to transform base metals such as lead or copper into silver or gold and to discover a cure for disease and a way of extending life\n",
      "labels:  Alchemy\n",
      "predicted labels:  Alchemy\n",
      "text:  the technique of photographing successive drawings or positions of puppets or models to create an illusion of movement when the movie is shown as a sequence.\n",
      "labels:  Animation\n",
      "predicted labels:  Animation\n",
      "text:  The objective of the game is to throw (shoot) a ball through the top of a circular band (referred to as the rim) that has cord hanging around its circumference (with both being named the basket), which is itself attached to a backboard\n",
      "labels:  Basketball\n",
      "predicted labels:  Basketball\n",
      "text:  the study of human biological and physiological characteristics and their evolution\n",
      "labels:  Anthropology\n",
      "predicted labels:  Anthropology\n",
      "text:  a cold-blooded vertebrate animal of a class that comprises the frogs, toads, newts, and salamanders. They are distinguished by having an aquatic gill-breathing larval stage followed (typically) by a terrestrial lung-breathing adult stage.\n",
      "labels:  Amphibian\n",
      "predicted labels:  Amphibian\n",
      "text:  cold-blooded vertebrates (vertebrates have backbones) that don’t have scales. They live part of their lives in water and part on land.\n",
      "labels:  Amphibian\n",
      "predicted labels:  Amphibian\n",
      "text:  studies celestial objects and phenomena in the universe. They explore and investigate various aspects of the cosmos, including stars, planets, galaxies, asteroids, comets, and other celestial bodies\n",
      "labels:  Astronomer\n",
      "predicted labels:  Astronomer\n",
      "text:  the organization of society on the basis of voluntary cooperation, without political institutions or hierarchical government\n",
      "labels:  Anarchism\n",
      "predicted labels:  Anarchism\n",
      "text:  They use telescopes, both on the ground and in space, to observe and collect data from distant objects. They analyze the light emitted or reflected by celestial bodies to determine their properties, such as their composition, temperature, distance, and motion\n",
      "labels:  Astronomer\n",
      "predicted labels:  Astronomer\n",
      "text:  the study of human societies and cultures and their development\n",
      "labels:  Anthropology\n",
      "predicted labels:  Anthropology\n",
      "text:  the science or practice of farming, including cultivation of the soil for the growing of crops and the rearing of animals to provide food, wool, and other products.\n",
      "labels:  Agriculture\n",
      "predicted labels:  Agriculture\n",
      "text:  the broad term for everything that goes into growing crops and raising animals, to provide food and materials that people can use and enjoy\n",
      "labels:  Agriculture\n",
      "predicted labels:  Agriculture\n",
      "text:  the manipulation of electronic images by means of a computer in order to create moving images.\n",
      "labels:  Animation\n",
      "predicted labels:  Animation\n",
      "text:  the largest state in the union and; one-fifth the size of the lower 48 states\n",
      "labels:  Alaska\n",
      "predicted labels:  Alaska\n",
      "text:  small vertebrates that need water, or a moist environment, to survive. The species in this group include frogs, toads, salamanders, and newts. All can breathe and absorb water through their very thin skin.\n",
      "labels:  Amphibian\n",
      "predicted labels:  Amphibian\n",
      "[Training][50] loss: 0.000\n",
      "[Validation][50] loss: 0.059\n",
      "[Validation]50 accuracy: 0.944\n"
     ]
    }
   ],
   "source": [
    "probe, _ = scripts.train_handler(train_dataset, val_dataset, label_encoder_title, probe_type=PROBE_TYPE, labels=LABELS, batch_size=BATCH_SIZE, epochs=EPOCHS, print_progress=PRINT_PROGRESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Editing With Linear Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 4096])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe.fc1.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Agriculture', 'Alaska', 'Alchemy', 'Algae', 'American football',\n",
       "       'Amphibian', 'Anarchism', 'Animation', 'Anthropology',\n",
       "       'Appellate court', 'Astronomer', 'Basketball'], dtype='<U17')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder_title.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"I hate authority and my favorite form of government is\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').input_ids.to(device)\n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11, 4096])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 4096])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = editable_model(input_ids, output_hidden_states=True)\n",
    "output.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 32001])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model.lm_head(output.hidden_states[-1])\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32001) must match the size of tensor b (4096) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/tnief/wiki-probes/train-notebook.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bg007.ds/home/tnief/wiki-probes/train-notebook.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m logits_mod \u001b[39m=\u001b[39m logits[:,\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,:] \u001b[39m-\u001b[39;49m probe\u001b[39m.\u001b[39;49mfc1\u001b[39m.\u001b[39;49mweight\u001b[39m.\u001b[39;49mdata[\u001b[39m6\u001b[39;49m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32001) must match the size of tensor b (4096) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "logits_mod = logits[:,-1,:] - probe.fc1.weight.data[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token = logits[:,-1,:].argmax(-1)\n",
    "next_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'an'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text = tokenizer.decode(next_token, skip_special_tokens=True)\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try modifying the final layer of the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n",
      "torch.Size([1, 1, 4096])\n"
     ]
    }
   ],
   "source": [
    "output = editable_model.generate(input_ids, max_length=50, num_return_sequences=1, output_hidden_states=True) # default search strategy is greedy\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I hate authority and my favorite form of government is anarchy.\\nI'm a big fan of the idea of a free society, but I'm not sure that anarchy is the way to get there.\\nI think that an\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Inheriting Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/modeling_llama.py#L989\n",
    "\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "class EditableLlama(LlamaForCausalLM):\n",
    "    def __init__(self, config, edit=None, *args, **kwargs):\n",
    "        super().__init__(config, *args, **kwargs)\n",
    "        self.edit = edit\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, CausalLMOutputWithPast]:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "                Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n",
    "                config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored\n",
    "                (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`.\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        Example:\n",
    "\n",
    "        ```python\n",
    "        >>> from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "\n",
    "        >>> model = LlamaForCausalLM.from_pretrained(PATH_TO_CONVERTED_WEIGHTS)\n",
    "        >>> tokenizer = AutoTokenizer.from_pretrained(PATH_TO_CONVERTED_TOKENIZER)\n",
    "\n",
    "        >>> prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
    "        >>> inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "        >>> # Generate\n",
    "        >>> generate_ids = model.generate(inputs.input_ids, max_length=30)\n",
    "        >>> tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "        \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\n",
    "        ```\"\"\"\n",
    "\n",
    "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        # decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs[0]\n",
    "        # TODO: Insert model edit here\n",
    "        # torch.Size([1, 11, 4096])\n",
    "        # torch.Size([1, 1, 4096])\n",
    "\n",
    "        hidden_states = hidden_states + torch.rand(4096)\n",
    "\n",
    "        if self.config.pretraining_tp > 1:\n",
    "            lm_head_slices = self.lm_head.weight.split(self.vocab_size // self.config.pretraining_tp, dim=0)\n",
    "            logits = [F.linear(hidden_states, lm_head_slices[i]) for i in range(self.config.pretraining_tp)]\n",
    "            logits = torch.cat(logits, dim=-1)\n",
    "        else:\n",
    "            logits = self.lm_head(hidden_states)\n",
    "        logits = logits.float()\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Shift so that tokens < n predict n\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            # Flatten the tokens\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            shift_logits = shift_logits.view(-1, self.config.vocab_size)\n",
    "            shift_labels = shift_labels.view(-1)\n",
    "            # Enable model parallelism\n",
    "            shift_labels = shift_labels.to(shift_logits.device)\n",
    "            loss = loss_fct(shift_logits, shift_labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return (loss,) + output if loss is not None else output\n",
    "\n",
    "        return CausalLMOutputWithPast(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            past_key_values=outputs.past_key_values,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0659aaba5645c5a3505be69ffe777f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL_PATH)\n",
    "editable_model = EditableLlama.from_pretrained(MODEL_PATH, low_cpu_mem_usage=True, torch_dtype=torch.float16, device_map=\"auto\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wiki-probes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
